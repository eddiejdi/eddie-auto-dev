# üöÄ Melhorias no Algoritmo de Compatibilidade

## üìä Algoritmo Atual (Jaccard Similarity)

**Pr√≥s:**
- ‚úÖ Simples e r√°pido
- ‚úÖ Independente do tamanho do texto
- ‚úÖ Funciona para overlap direto de palavras-chave

**Contras:**
- ‚ùå N√£o considera sin√¥nimos (Kubernetes ‚â† K8s, CI/CD ‚â† pipeline)
- ‚ùå N√£o entende contexto sem√¢ntico
- ‚ùå Todas as palavras t√™m o mesmo peso
- ‚ùå Ordem e contexto s√£o ignorados

**Resultado:** Max 1.1% nos seus grupos do WhatsApp

---

## üéØ Melhorias Propostas

### 1Ô∏è‚É£ **TF-IDF Weighting** (F√°cil, +30% precis√£o)

**O que √©:** Dar mais peso a palavras **raras e t√©cnicas**, menos peso a palavras comuns.

**Exemplo:**
- "kubernetes" = peso alto (raro, t√©cnico)
- "experi√™ncia" = peso baixo (comum em todas as √°reas)

**Implementa√ß√£o:**
```python
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

def compute_compatibility_tfidf(resume_text, job_text):
    vectorizer = TfidfVectorizer(stop_words=stopwords, min_df=1)
    vectors = vectorizer.fit_transform([resume_text, job_text])
    similarity = cosine_similarity(vectors[0], vectors[1])[0][0]
    return round(similarity * 100, 1)
```

**Benef√≠cio:** Vagas com "kubernetes docker terraform" teriam score muito maior que vagas com "vaga nova remota".

---

### 2Ô∏è‚É£ **Dicion√°rio de Sin√¥nimos T√©cnicos** (M√©dio, +50% recall)

**O que √©:** Mapear termos equivalentes antes de comparar.

**Exemplo:**
```python
TECH_SYNONYMS = {
    'kubernetes': ['k8s', 'kube', 'orchestration'],
    'ci/cd': ['pipeline', 'continuous', 'integration', 'deployment'],
    'infrastructure': ['infra', 'plataforma', 'platform'],
    'devops': ['sre', 'site reliability', 'platform engineer'],
    'aws': ['amazon', 'ec2', 's3', 'lambda'],
    'gcp': ['google cloud', 'gke', 'cloud run'],
}

def expand_tokens(tokens):
    expanded = set(tokens)
    for token in tokens:
        if token in TECH_SYNONYMS:
            expanded.update(TECH_SYNONYMS[token])
    return expanded
```

**Benef√≠cio:** Vaga com "Procuramos SRE com experi√™ncia em K8s" teria overlap com seu curr√≠culo mesmo sem usar "Kubernetes" exato.

---

### 3Ô∏è‚É£ **Sentence Embeddings (Semantic)** (Avan√ßado, +80% precis√£o)

**O que √©:** Usar modelos de linguagem para entender **significado sem√¢ntico**, n√£o apenas palavras literais.

**Modelos dispon√≠veis:**
- `sentence-transformers/paraphrase-multilingual-mpnet-base-v2` (portugu√™s)
- `sentence-transformers/all-MiniLM-L6-v2` (ingl√™s, mais r√°pido)

**Implementa√ß√£o:**
```python
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity

model = SentenceTransformer('paraphrase-multilingual-mpnet-base-v2')

def compute_compatibility_semantic(resume_text, job_text):
    embeddings = model.encode([resume_text, job_text])
    similarity = cosine_similarity([embeddings[0]], [embeddings[1]])[0][0]
    return round(similarity * 100, 1)
```

**Benef√≠cio:** Entende que "Vaga para engenheiro de plataforma Kubernetes" √© similar a "DevOps com experi√™ncia em orquestra√ß√£o de containers" **mesmo sem palavras exatas em comum**.

**Desvantagem:** Requer modelo ML (~500MB), processamento mais lento (mas ainda <1s por vaga).

---

### 4Ô∏è‚É£ **Extra√ß√£o de Entidades (NER)** (Avan√ßado, +60% precis√£o)

**O que √©:** Identificar e comparar **entidades espec√≠ficas** (tecnologias, ferramentas, certifica√ß√µes).

**Exemplo:**
```python
import spacy

nlp = spacy.load("pt_core_news_lg")

def extract_tech_entities(text):
    doc = nlp(text)
    techs = set()
    
    # Identificar tecnologias conhecidas
    for ent in doc.ents:
        if ent.label_ in ['PRODUCT', 'ORG']:  # Kubernetes, AWS, Docker, etc.
            techs.add(ent.text.lower())
    
    # Pattern matching adicional
    tech_keywords = ['kubernetes', 'docker', 'terraform', 'ansible', 'aws', 'gcp', 'azure', ...]
    for keyword in tech_keywords:
        if keyword in text.lower():
            techs.add(keyword)
    
    return techs
```

**Benef√≠cio:** Foca apenas em tecnologias relevantes, ignora texto descritivo gen√©rico.

---

## üéØ Recomenda√ß√£o por Prioridade

### ‚úÖ **R√°pido (hoje mesmo):**
1. Ajustar threshold para **0.5-1.0%** baseado nos dados reais
2. Adicionar dicion√°rio de sin√¥nimos t√©cnicos (50 linhas de c√≥digo)

### üöÄ **Curto prazo (1-2 dias):**
3. Implementar TF-IDF weighting
4. Melhorar extra√ß√£o de texto do .docx (atualmente hardcoded)

### üåü **Longo prazo (1 semana):**
5. Integrar sentence-transformers para matching sem√¢ntico
6. Criar dashboard com visualiza√ß√£o de scores e palavras-chave

---

## üìä Compara√ß√£o de Abordagens

| M√©todo | Precis√£o | Speed | Complexidade | Req. Ext. |
|--------|----------|-------|--------------|-----------|
| **Jaccard (atual)** | ‚≠ê‚≠ê | ‚ö°‚ö°‚ö° | üü¢ Baixa | Nenhum |
| **TF-IDF** | ‚≠ê‚≠ê‚≠ê | ‚ö°‚ö°‚ö° | üü° M√©dia | sklearn |
| **Sin√¥nimos** | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚ö°‚ö°‚ö° | üü¢ Baixa | Dicion√°rio |
| **Embeddings** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚ö°‚ö° | üî¥ Alta | 500MB model |
| **NER + Rules** | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚ö°‚ö° | üî¥ Alta | spaCy |

---

## üõ†Ô∏è Quer que eu implemente alguma dessas melhorias?

Posso fazer agora:
1. ‚úÖ **TF-IDF + Sin√¥nimos** (30 minutos, +70% melhoria)
2. ‚úÖ **Sentence Embeddings** (1 hora, +80% melhoria, download 500MB)
3. ‚úÖ **Hybrid approach** (Jaccard + TF-IDF + Sin√¥nimos = melhor custo-benef√≠cio)

Basta me dizer qual prefere! üöÄ
