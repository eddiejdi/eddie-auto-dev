groups:
  - name: eddie_alerts
    interval: 30s
    rules:
      # Alert 1: API Health
      - alert: APIDown
        expr: up{job="eddie-api"} == 0
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: "Eddie API estÃ¡ down"
          description: "A API especializada (eddie-api:8503) nÃ£o estÃ¡ respondendo por mais de 2 minutos"

      # Alert 2: High Memory Usage
      - alert: HighMemoryUsage
        expr: (container_memory_usage_bytes / container_memory_max_bytes) > 0.85
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Alto uso de memÃ³ria detectado"
          description: "Container {{ $labels.container_label_com_docker_compose_service }} usando mais de 85% de memÃ³ria"

      # Alert 3: High CPU Usage
      - alert: HighCPUUsage
        expr: rate(container_cpu_usage_seconds_total[5m]) > 0.8
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Alto uso de CPU detectado"
          description: "Container {{ $labels.container_label_com_docker_compose_service }} usando mais de 80% de CPU"

      # Alert 4: Prometheus Storage Full
      - alert: PrometheusStorageFull
        expr: (node_filesystem_avail_bytes{mountpoint="/prometheus"} / node_filesystem_size_bytes) < 0.1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Storage do Prometheus quase cheio"
          description: "Apenas {{ $value | humanizePercentage }} de espaÃ§o disponÃ­vel"
  - name: trading_agent_alerts
    interval: 15s
    rules:
      # Trading Alert 1: Agent Down â€” systemd not active
      - alert: TradingAgentDown
        expr: trading_agent_up == 0
        for: 3m
        labels:
          severity: critical
          component: trading
        annotations:
          summary: "ðŸ”´ Trading Agent {{ $labels.symbol }} DOWN"
          description: "Agent {{ $labels.symbol }} Ã© estÃ¡ inativo por mais de 3 minutos. Systemd unit pode estar crashed."
          dashboard: "https://grafana.rpa4all.com/d/237610b0-trading-agent-monitor"

      # Trading Alert 2: Agent Stalled â€” not producing decisions
      - alert: TradingAgentStalled
        expr: trading_agent_stalled == 1
        for: 5m
        labels:
          severity: warning
          component: trading
        annotations:
          summary: "â¸ï¸ Trading Agent {{ $labels.symbol }} STALLED"
          description: "Agent {{ $labels.symbol }} nÃ£o gerou decisÃµes por mais de 5 minutos. PossÃ­vel deadlock na DB ou timeout na API KuCoin."
          dashboard: "https://grafana.rpa4all.com/d/237610b0-trading-agent-monitor"

      # Trading Alert 3: Decisions Gap â€” no activity for too long
      - alert: TradingDecisionsGap
        expr: trading_agent_last_decision_age_seconds > 900
        for: 3m
        labels:
          severity: warning
          component: trading
        annotations:
          summary: "â³ Trading Agent {{ $labels.symbol }} â€” Decisions Gap 15+ min"
          description: "Agent {{ $labels.symbol }} nÃ£o gerou decisÃ£o hÃ¡ {{ $value | humanizeDuration }}. Self-heal pode executar restart."

      # Trading Alert 4: Self-Healing Exhausted â€” too many consecutive failures
      - alert: TradingSelfHealExhausted
        expr: trading_agent_consecutive_failures > 6
        for: 2m
        labels:
          severity: critical
          component: trading
        annotations:
          summary: "ðŸš¨ Trading Agent {{ $labels.symbol }} â€” Self-Heal FAILED"
          description: "Agent {{ $labels.symbol }} failed health checks {{ $value | humanize }} times. Auto-restart nÃ£o conseguiu recuperar. IntervenÃ§Ã£o manual necessÃ¡ria."
          dashboard: "https://grafana.rpa4all.com/d/237610b0-trading-agent-monitor"
          runbook: "Check logs: journalctl -u crypto-agent@{{ $labels.symbol }}.service -n 100"

      # Trading Alert 5: Exporter Down â€” can't scrape metrics
      - alert: TradingExporterDown
        expr: up{job="crypto-exporters"} == 0
        for: 2m
        labels:
          severity: critical
          component: trading
        annotations:
          summary: "ðŸ”Œ Trading Exporter {{ $labels.symbol }} â€” Prometheus scrape FAILED"
          description: "NÃ£o conseguindo scrape metrics do exporter. Port 909X pode estar bloqueada ou processo morreu."
          dashboard: "https://grafana.rpa4all.com/d/237610b0-trading-agent-monitor"

      # Trading Alert 6: Ollama Analysis Failed â€” diagnostic engine down
      - alert: TradingOllamaAnalysisFailed
        expr: increase(trading_selfheal_actions_total{action="ollama_error"}[1h]) > 5
        for: 5m
        labels:
          severity: warning
          component: ollama
        annotations:
          summary: "âš¡ Trading Self-Heal â€” Ollama Diagnostics Failing"
          description: "Ollama analysis failed {{ $value | humanize }} times in last hour. LLM root-cause detection disabled but restarts continue."
          hint: "Check Ollama health: curl -s http://192.168.15.2:11434/api/tags | jq"

      # Trading Alert 7: Too many restarts in last hour â€” rate limit engaged
      - alert: TradingAgentRestartRateLimit
        expr: rate(trading_agent_restart_total[1h]) > 3
        for: 5m
        labels:
          severity: warning
          component: trading
        annotations:
          summary: "âš™ï¸ Trading Agent {{ $labels.symbol }} â€” Restart Rate Limit"
          description: "Agent {{ $labels.symbol }} was restarted > 3 times in last hour. Self-heal rate-limited to prevent thrashing."
          hint: "Check audit log: curl -s http://192.168.15.2:9121/audit | jq '.[] | select(.symbol==\"{{ $labels.symbol }}\")'  | tail -20"