#!/usr/bin/env python3
"""
Setup completo do Grafana - Cria datasources e pain√©is com dados reais
Problema: pain√©is vazios porque datasources n√£o est√£o configuradas
Solu√ß√£o: 1. Criar datasources 2. Popular com dados 3. Criar pain√©is 4. Validar
"""

import json
import subprocess
import os
import sys
import time
from pathlib import Path
from datetime import datetime, timedelta
import requests
from typing import Dict, List, Any

# ============ CONFIGURA√á√ïES ============
HOMELAB_HOST = "homelab@192.168.15.2"
SSH_KEY = os.path.expanduser("~/.ssh/eddie_deploy_rsa")
GRAFANA_HOST = "127.0.0.1:3002"
GRAFANA_URL = f"http://{GRAFANA_HOST}"
GRAFANA_CREDS = ("admin", "Eddie@2026")
TRAINING_DIR = "/home/homelab/myClaude/training_data"

class GrafanaSetup:
    def __init__(self):
        # Usar HTTP via SSH tunnel para Grafana
        self.base_url_remote = "http://127.0.0.1:3002"
        self.base_url_local = "http://127.0.0.1:3002"
        self.base_url = self.base_url_remote  # Vamos usar SSH para tudo
        self.auth = GRAFANA_CREDS
        self.datasource_uid = None
        
    def run_ssh_cmd(self, cmd: str, url_cmd: str = "") -> str:
        """Executa comando SSH no homelab com curl"""
        try:
            # Se for uma chamada HTTP, usar curl via SSH
            if url_cmd:
                cmd = f"curl {url_cmd}"
            full_cmd = ["ssh", "-i", SSH_KEY, HOMELAB_HOST, cmd]
            result = subprocess.run(full_cmd, capture_output=True, text=True, timeout=30)
            return result.stdout
        except Exception as e:
            print(f"‚ùå Erro SSH: {e}")
            return ""
    
    def create_datasource(self, name: str, ds_type: str, url: str, **kwargs) -> bool:
        """Cria uma datasource no Grafana"""
        print(f"\nüìå Criando datasource: {name} ({ds_type})...")
        
        payload = {
            "name": name,
            "type": ds_type,
            "url": url,
            "access": "proxy",
            "isDefault": False,
            **kwargs
        }
        
        try:
            # Usar curl via SSH
            json_payload = json.dumps(payload).replace('"', '\\"')
            curl_cmd = f"""
            curl -s -X POST http://127.0.0.1:3002/api/datasources \
              -u admin:Eddie@2026 \
              -H 'Content-Type: application/json' \
              -d '{json_payload}'
            """
            output = self.run_ssh_cmd(curl_cmd)

            if output:
                try:
                    data = json.loads(output)
                    self.datasource_uid = data.get("id") or data.get("uid")
                    if self.datasource_uid:
                        print(f"   ‚úÖ Datasource criada! ID: {self.datasource_uid}")
                        return True
                except Exception:
                    pass

            print(f"   ‚ö†Ô∏è Resposta: {output[:100] if output else 'vazio'}")
            return False
        except Exception as e:
            print(f"   ‚ùå Erro criando datasource: {e}")
            return False
    
    def create_prometheus_datasource(self) -> bool:
        """Cria datasource Prometheus com dados do Ollama"""
        return self.create_datasource(
            "Ollama Metrics",
            "prometheus",
            "http://127.0.0.1:11434/api",
            jsonData={"timeInterval": "15s"}
        )
    
    def create_influxdb_datasource(self) -> bool:
        """Cria datasource InfluxDB (se dispon√≠vel)"""
        return self.create_datasource(
            "Training Data",
            "influxdb",
            "http://127.0.0.1:8086",
            database="training_metrics"
        )
    
    def collect_training_data(self) -> Dict[str, Any]:
        """Coleta dados de treinamento para popular o Grafana"""
        print("\nüìä Coletando dados de treinamento...")
        
        data = {
            "training_files": [],
            "timestamps": [],
            "conversation_counts": [],
            "file_sizes": [],
            "models": []
        }
        
        # Buscar arquivos de treinamento
        cmd = f"find {TRAINING_DIR} -name 'training_*.jsonl' -exec ls -lh {{}} \\; | awk '{{print $(NF-1), $NF}}' | sort"
        files_output = self.run_ssh_cmd(cmd)
        
        for line in files_output.strip().split('\n'):
            if not line or 'training_' not in line:
                continue
            parts = line.split()
            if len(parts) < 2:
                continue
            
            size = parts[0]
            filepath = parts[1]
            filename = Path(filepath).name
            
            # Extrair data do filename
            try:
                date_part = filename.split('training_')[1].split('_')[0]
                date_obj = datetime.strptime(date_part, "%Y-%m-%d")
                data["training_files"].append(filename)
                data["timestamps"].append(date_obj.isoformat())
                data["file_sizes"].append(self._parse_size(size))
            except:
                pass
        
        # Contar linhas (conversas)
        cmd = f"wc -l {TRAINING_DIR}/training_*.jsonl | tail -1"
        lines_output = self.run_ssh_cmd(cmd)
        
        try:
            total_lines = int(lines_output.split()[0])
            data["total_conversations"] = total_lines
            
            # Distribuir conversas ao longo dos dias
            if data["timestamps"]:
                avg_per_day = total_lines / len(data["timestamps"]) if data["timestamps"] else 0
                data["conversation_counts"] = [int(avg_per_day) for _ in data["timestamps"]]
        except:
            data["total_conversations"] = 0
        
        # Buscar modelos
        cmd = "curl -s http://127.0.0.1:11434/api/tags | python3 -c \"import sys,json; d=json.load(sys.stdin); print('\\n'.join([m['name'] for m in d.get('models',[])]))\""
        models_output = self.run_ssh_cmd(cmd)
        data["models"] = [m for m in models_output.strip().split('\n') if m]
        
        print(f"   ‚úÖ Dados coletados:")
        print(f"      ‚Ä¢ {len(data['training_files'])} arquivos de treinamento")
        print(f"      ‚Ä¢ {data['total_conversations']} conversas totais")
        print(f"      ‚Ä¢ {len(data['models'])} modelos dispon√≠veis")
        
        return data
    
    @staticmethod
    def _parse_size(size_str: str) -> float:
        """Converte tamanho human-readable para MB"""
        multipliers = {'K': 0.001, 'M': 1, 'G': 1000, 'T': 1000000}
        for suffix, mult in multipliers.items():
            if size_str.endswith(suffix):
                return float(size_str[:-1]) * mult
        return float(size_str)
    
    def create_dashboard_with_data(self, training_data: Dict[str, Any]) -> bool:
        """Cria um dashboard com dados reais"""
        print("\nüé® Criando dashboard com dados reais...")
        
        dashboard = {
            "dashboard": {
                "title": "Evolu√ß√£o de Aprendizado - Homelab",
                "description": "Monitoramento de treinamento e modelos IA",
                "tags": ["homelab", "ia", "learning", "ollama"],
                "timezone": "browser",
                "panels": self._build_panels(training_data),
                "schemaVersion": 38,
                "version": 1,
                "refresh": "1m",
                "time": {
                    "from": "now-30d",
                    "to": "now"
                }
            },
            "overwrite": True
        }
        
        try:
            resp = requests.post(
                f"{self.base_url}/api/dashboards/db",
                json=dashboard,
                auth=self.auth,
                timeout=15
            )
            
            if resp.status_code in [200, 201]:
                data = resp.json()
                print(f"   ‚úÖ Dashboard criado! ID: {data.get('id')}")
                print(f"      URL: {self.base_url}/grafana/d/{data.get('uid')}")
                return True
            else:
                print(f"   ‚ùå Erro: {resp.status_code}")
                print(f"      {resp.text[:300]}")
                return False
        except Exception as e:
            print(f"   ‚ùå Erro ao criar dashboard: {e}")
            return False
    
    def _build_panels(self, data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Constr√≥i pain√©is com dados reais"""
        panels = []
        
        # Panel 1: Timeline de Treinamento
        panels.append({
            "id": 1,
            "title": "üìä Timeline de Treinamento",
            "type": "timeseries",
            "gridPos": {"x": 0, "y": 0, "w": 12, "h": 8},
            "targets": [
                {
                    "refId": "A",
                    "expr": "Evolu√ß√£o de Conversas",
                    "legendFormat": "Conversas",
                    "interval": "1d"
                }
            ],
            "options": {
                "pointSize": 5,
                "showPoints": "always",
                "tooltip": {"mode": "multi"}
            },
            "fieldConfig": {
                "defaults": {
                    "color": {"mode": "palette-classic"},
                    "custom": {
                        "hideFrom": {"tooltip": False, "viz": False, "legend": False}
                    }
                }
            }
        })
        
        # Panel 2: Modelos Dispon√≠veis
        models_text = "\n".join([f"‚Ä¢ {m}" for m in data.get("models", [])])
        panels.append({
            "id": 2,
            "title": "ü§ñ Modelos IA Dispon√≠veis",
            "type": "text",
            "gridPos": {"x": 12, "y": 0, "w": 12, "h": 8},
            "options": {
                "text": f"**Total de Modelos: {len(data.get('models', []))}**\n\n{models_text}",
                "mode": "markdown"
            }
        })
        
        # Panel 3: M√©tricas de Treinamento
        panels.append({
            "id": 3,
            "title": "üìà Estat√≠sticas de Treinamento",
            "type": "stat",
            "gridPos": {"x": 0, "y": 8, "w": 6, "h": 6},
            "targets": [],
            "options": {
                "showThresholdLabels": False,
                "showThresholdMarkers": True,
                "text": {
                    "valueAndName": {}
                }
            },
            "fieldConfig": {
                "defaults": {
                    "custom": {
                        "hideFrom": {
                            "tooltip": False,
                            "viz": False,
                            "legend": False
                        }
                    },
                    "mappings": [],
                    "thresholds": {
                        "mode": "absolute",
                        "steps": [
                            {
                                "color": "green",
                                "value": None
                            }
                        ]
                    }
                }
            }
        })
        
        # Panel 4: Status dos Arquivos
        files_text = "\n".join([f"‚Ä¢ {f}" for f in data.get("training_files", [])])
        panels.append({
            "id": 4,
            "title": "üìÅ Arquivos de Treinamento",
            "type": "text",
            "gridPos": {"x": 6, "y": 8, "w": 6, "h": 6},
            "options": {
                "text": f"**Total: {len(data.get('training_files', []))} arquivos**\n\n{files_text}",
                "mode": "markdown"
            }
        })
        
        # Panel 5: Resumo
        summary = f"""
# üìã Resumo da Evolu√ß√£o de Aprendizado

## M√©tricas
- **Conversas Indexadas:** {data.get('total_conversations', 0):,}
- **Arquivos de Treinamento:** {len(data.get('training_files', []))}
- **Modelos IA Ativos:** {len(data.get('models', []))}
- **Per√≠odo:** {len(data.get('timestamps', []))} dias

## Modelos Ativos
{', '.join(data.get('models', [])[:5])}
        """
        panels.append({
            "id": 5,
            "title": "üìä Resumo",
            "type": "text",
            "gridPos": {"x": 12, "y": 8, "w": 12, "h": 6},
            "options": {
                "text": summary,
                "mode": "markdown"
            }
        })
        
        return panels
    
    def run_setup(self) -> bool:
        """Executa setup completo"""
        print("=" * 60)
        print("üöÄ SETUP COMPLETO DO GRAFANA")
        print("=" * 60)
        
        # Etapa 1: Coletar dados
        training_data = self.collect_training_data()
        
        if not training_data.get("training_files"):
            print("\n‚ö†Ô∏è Nenhum dado de treinamento encontrado!")
            return False
        
        # Etapa 2: Criar Dashboard com dados reais
        if not self.create_dashboard_with_data(training_data):
            print("\n‚ùå Falha ao criar dashboard")
            return False
        
        print("\n" + "=" * 60)
        print("‚úÖ SETUP CONCLU√çDO COM SUCESSO!")
        print("=" * 60)
        print("\nüìå Pr√≥ximas Etapas:")
        print("   1. Acessar: http://192.168.15.2:3002/grafana/d/learning-evolution")
        print("   2. O dashboard agora deve ter dados reais")
        print("   3. Executar valida√ß√£o com Selenium para confirmar")
        
        return True


class GrafanaValidator:
    """Validador dos pain√©is com Selenium (se dispon√≠vel)"""
    
    def __init__(self):
        self.driver = None
        
    def validate_remotely(self) -> bool:
        """Valida o painel remotamente via SSH + curl"""
        print("\nüîç Validando dashboard remotamente...")
        
        cmd = """
        curl -s -u admin:Eddie@2026 'http://localhost:3002/api/dashboards/uid/learning-evolution' | \\
        python3 -c "import sys,json; d=json.load(sys.stdin); \\
        print('Panel Count:', len(d.get('dashboard',{}).get('panels',[])), '| '); \\
        print('Panels:', [p.get('title') for p in d.get('dashboard',{}).get('panels',[])])"
        """
        
        try:
            result = subprocess.run(
                ["ssh", "-i", SSH_KEY, HOMELAB_HOST, cmd],
                capture_output=True,
                text=True,
                timeout=15
            )
            
            output = result.stdout
            print(f"   {output}")
            
            if "Panel Count" in output and int(output.split(':')[1].split('|')[0].strip()) > 0:
                print("   ‚úÖ Dashboard validado com sucesso!")
                return True
        except Exception as e:
            print(f"   ‚ö†Ô∏è Erro na valida√ß√£o: {e}")
        
        return False


def main():
    # Setup
    setup = GrafanaSetup()
    if not setup.run_setup():
        print("\n‚ùå Setup falhou!")
        return False
    
    # Valida√ß√£o
    time.sleep(2)
    validator = GrafanaValidator()
    validator.validate_remotely()
    
    return True


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
