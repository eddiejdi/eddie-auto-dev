#!/usr/bin/env python3
"""
Processador de Chats do VS Code para Treinamento
"""

import os
import json
import glob
from pathlib import Path
from datetime import datetime
import requests

# Configura√ß√µes
OLLAMA_HOST = "http://192.168.15.2:11434"
BASE_DIR = Path("/home/eddie/myClaude/training_data")
CHATS_DIR = BASE_DIR / "chats_raw"
TODAY = datetime.now().strftime("%Y-%m-%d")

def load_all_chats():
    """Carrega todos os chats do diret√≥rio"""
    chats = []
    
    for chat_file in CHATS_DIR.glob("*.json"):
        try:
            with open(chat_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                chats.append({
                    'file': str(chat_file),
                    'name': chat_file.stem,
                    'data': data
                })
                print(f"‚úÖ Carregado: {chat_file.name}")
        except Exception as e:
            print(f"‚ö†Ô∏è Erro em {chat_file.name}: {e}")
    
    return chats

def extract_conversations(chats):
    """Extrai pares de prompt/resposta dos chats"""
    conversations = []
    
    for chat in chats:
        data = chat['data']
        
        # Formato VS Code Copilot Chat
        requests_list = data.get('requests', [])
        
        for req in requests_list:
            try:
                # Extrair mensagem do usu√°rio
                prompt = ""
                if 'message' in req:
                    msg = req['message']
                    if isinstance(msg, dict):
                        prompt = msg.get('text', msg.get('content', ''))
                    else:
                        prompt = str(msg)
                
                # Extrair resposta
                response_text = ""
                if 'response' in req:
                    resp = req['response']
                    
                    # Pode ser uma lista de partes
                    if isinstance(resp, list):
                        parts = []
                        for part in resp:
                            if isinstance(part, dict):
                                parts.append(part.get('value', part.get('content', '')))
                            else:
                                parts.append(str(part))
                        response_text = '\n'.join(parts)
                    
                    # Ou pode ser um dict com 'value'
                    elif isinstance(resp, dict):
                        if 'value' in resp:
                            val = resp['value']
                            if isinstance(val, list):
                                parts = []
                                for v in val:
                                    if isinstance(v, dict):
                                        parts.append(v.get('value', v.get('content', '')))
                                    else:
                                        parts.append(str(v))
                                response_text = '\n'.join(parts)
                            else:
                                response_text = str(val)
                        else:
                            response_text = resp.get('content', resp.get('text', str(resp)))
                    else:
                        response_text = str(resp)
                
                # Limpar e validar
                prompt = prompt.strip()
                response_text = response_text.strip()
                
                if prompt and response_text and len(prompt) > 5 and len(response_text) > 10:
                    conversations.append({
                        'prompt': prompt,
                        'response': response_text,
                        'source': chat['name']
                    })
                    
            except Exception as e:
                continue
    
    return conversations

def create_training_data(conversations):
    """Cria arquivo JSONL para treinamento"""
    output_file = BASE_DIR / f"training_{TODAY}.jsonl"
    
    with open(output_file, 'w', encoding='utf-8') as f:
        for conv in conversations:
            item = {
                "instruction": conv['prompt'],
                "output": conv['response'],
                "input": ""
            }
            f.write(json.dumps(item, ensure_ascii=False) + '\n')
    
    print(f"\nüìù Arquivo de treinamento: {output_file}")
    print(f"   {len(conversations)} exemplos de treinamento")
    
    return output_file, conversations

def create_enhanced_modelfile(conversations, base_model="codestral:22b"):
    """Cria Modelfile com contexto aprendido"""
    
    # Criar resumo dos t√≥picos abordados
    topics = set()
    for conv in conversations[:50]:  # An√°lise das primeiras 50
        prompt_lower = conv['prompt'].lower()
        
        if any(w in prompt_lower for w in ['python', 'pip', 'venv']):
            topics.add("Python e ambientes virtuais")
        if any(w in prompt_lower for w in ['github', 'git', 'repo', 'commit']):
            topics.add("GitHub e controle de vers√£o")
        if any(w in prompt_lower for w in ['ollama', 'llm', 'model', 'train']):
            topics.add("Ollama e modelos de linguagem")
        if any(w in prompt_lower for w in ['docker', 'container', 'kubernetes']):
            topics.add("Docker e containeriza√ß√£o")
        if any(w in prompt_lower for w in ['api', 'rest', 'http', 'request']):
            topics.add("APIs e requisi√ß√µes HTTP")
        if any(w in prompt_lower for w in ['streamlit', 'flask', 'web']):
            topics.add("Desenvolvimento web")
        if any(w in prompt_lower for w in ['mcp', 'server', 'protocol']):
            topics.add("MCP e protocolos de integra√ß√£o")
        if any(w in prompt_lower for w in ['linux', 'bash', 'ssh', 'terminal']):
            topics.add("Linux e linha de comando")
    
    topics_str = '\n'.join([f"- {t}" for t in sorted(topics)])
    
    # Exemplos de intera√ß√µes (resumidos)
    examples = []
    for conv in conversations[:5]:
        prompt_short = conv['prompt'][:150] + "..." if len(conv['prompt']) > 150 else conv['prompt']
        examples.append(f"Usu√°rio: {prompt_short}")
    examples_str = '\n'.join(examples)
    
    modelfile = f'''FROM {base_model}

SYSTEM """Voc√™ √© Eddie Assistant, um assistente de programa√ß√£o altamente especializado.
Voc√™ foi treinado com {len(conversations)} conversas reais de desenvolvimento do dia {TODAY}.

## √Åreas de Especializa√ß√£o (baseado no treinamento de hoje):
{topics_str}

## Contexto de Aprendizado:
Este modelo foi personalizado com intera√ß√µes reais incluindo:
{examples_str}

## Diretrizes:
1. Forne√ßa c√≥digo funcional e testado
2. Explique o racioc√≠nio por tr√°s das solu√ß√µes
3. Use boas pr√°ticas de programa√ß√£o
4. Seja conciso mas completo
5. Responda em portugu√™s quando perguntado em portugu√™s
6. Para c√≥digo, use markdown com syntax highlighting

## Ambiente do Usu√°rio:
- Sistema: WSL Ubuntu no Windows
- Servidor Ollama: 192.168.15.2:11434
- Modelos dispon√≠veis: codestral:22b, deepseek-coder-v2:16b, qwen2.5-coder:7b
- Ferramentas: VS Code, GitHub, Docker
"""

PARAMETER temperature 0.3
PARAMETER top_p 0.9
PARAMETER num_ctx 8192
PARAMETER repeat_penalty 1.1
'''
    return modelfile

def train_model(conversations, base_model="codestral:22b"):
    """Cria modelo personalizado no Ollama"""
    
    model_name = f"eddie-assistant:{TODAY}"
    
    print(f"\nüöÄ Criando modelo {model_name}...")
    print(f"   Base: {base_model}")
    print(f"   Conversas: {len(conversations)}")
    
    # Criar Modelfile
    modelfile = create_enhanced_modelfile(conversations, base_model)
    
    # Salvar Modelfile
    modelfile_path = BASE_DIR / "Modelfile.latest"
    with open(modelfile_path, 'w', encoding='utf-8') as f:
        f.write(modelfile)
    print(f"üìÑ Modelfile salvo: {modelfile_path}")
    
    # Criar modelo via API
    try:
        print("\n‚è≥ Enviando para Ollama...")
        response = requests.post(
            f"{OLLAMA_HOST}/api/create",
            json={
                "name": model_name,
                "modelfile": modelfile
            },
            timeout=300,
            stream=True
        )
        
        for line in response.iter_lines():
            if line:
                try:
                    status = json.loads(line)
                    if 'status' in status:
                        print(f"   {status['status']}")
                except:
                    pass
        
        print(f"\n‚úÖ Modelo {model_name} criado com sucesso!")
        return model_name
        
    except requests.exceptions.ConnectionError:
        print(f"‚ùå N√£o foi poss√≠vel conectar ao Ollama em {OLLAMA_HOST}")
        print("   Verifique se o servidor est√° rodando.")
        return None
    except Exception as e:
        print(f"‚ùå Erro: {e}")
        return None

def update_continue_config(model_name):
    """Atualiza configura√ß√£o do Continue para usar o novo modelo"""
    config_path = Path.home() / ".continue" / "config.json"
    
    if config_path.exists():
        try:
            with open(config_path, 'r') as f:
                config = json.load(f)
            
            # Adicionar novo modelo √† lista
            new_model = {
                "title": f"Eddie Assistant ({TODAY})",
                "provider": "ollama",
                "model": model_name,
                "apiBase": OLLAMA_HOST
            }
            
            if 'models' in config:
                # Verificar se j√° existe
                exists = any(m.get('model') == model_name for m in config['models'])
                if not exists:
                    config['models'].insert(0, new_model)
                    
                    with open(config_path, 'w') as f:
                        json.dump(config, f, indent=2)
                    
                    print(f"üìù Continue atualizado com {model_name}")
        except Exception as e:
            print(f"‚ö†Ô∏è Erro ao atualizar Continue: {e}")

def main():
    print("=" * 60)
    print(f"ü§ñ Processamento de Chats e Treinamento - {TODAY}")
    print("=" * 60)
    
    # Verificar diret√≥rio de chats
    if not CHATS_DIR.exists():
        print(f"‚ùå Diret√≥rio n√£o encontrado: {CHATS_DIR}")
        return
    
    # Carregar chats
    print("\nüì• Carregando chats...")
    chats = load_all_chats()
    
    if not chats:
        print("‚ùå Nenhum chat encontrado!")
        return
    
    print(f"\n‚úÖ {len(chats)} arquivos carregados")
    
    # Extrair conversas
    print("\nüîç Extraindo conversas...")
    conversations = extract_conversations(chats)
    
    if not conversations:
        print("‚ùå Nenhuma conversa v√°lida extra√≠da!")
        return
    
    print(f"üí¨ {len(conversations)} conversas extra√≠das")
    
    # Mostrar algumas amostras
    print("\nüìã Amostras de conversas:")
    for i, conv in enumerate(conversations[:3]):
        print(f"\n  [{i+1}] Prompt: {conv['prompt'][:80]}...")
        print(f"      Response: {conv['response'][:80]}...")
    
    # Criar dados de treinamento
    print("\nüìù Criando dados de treinamento...")
    training_file, convs = create_training_data(conversations)
    
    # Treinar modelo
    model_name = train_model(conversations)
    
    if model_name:
        # Atualizar Continue
        update_continue_config(model_name)
        
        print("\n" + "=" * 60)
        print("üéâ TREINAMENTO CONCLU√çDO!")
        print("=" * 60)
        print(f"\nüì¶ Modelo: {model_name}")
        print(f"üìä Conversas: {len(conversations)}")
        print(f"üìÇ Dados: {BASE_DIR}")
        print(f"\nüí° Para usar:")
        print(f"   ollama run {model_name}")

if __name__ == "__main__":
    main()
