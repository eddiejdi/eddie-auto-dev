#!/usr/bin/env python3
"""
Script simplificado para atualizar RAG usando Ollama embeddings
"""

import os
import json
import hashlib
import requests
from datetime import datetime
from pathlib import Path
from typing import List, Dict
import chromadb

# Configura√ß√µes
BASE_DIR = Path(__file__).parent
TRAINING_DIR = BASE_DIR / "training_data"
CHROMA_DIR = BASE_DIR / "chroma_db"
DOCS_DIR = BASE_DIR / "docs"
OLLAMA_URL = "http://192.168.15.2:11434"

# Conhecimento da sess√£o atual
KNOWLEDGE = [
    {
        "id": "integration_openwebui",
        "topic": "Integra√ß√£o Open WebUI + Telegram + WhatsApp",
        "content": """Integra√ß√£o entre modelos Ollama, Open WebUI e bots.
        Open WebUI: http://192.168.15.2:3000
        Ollama: http://192.168.15.2:11434  
        WAHA: http://192.168.15.2:3001
        M√≥dulo: openwebui_integration.py com perfis autom√°ticos."""
    },
    {
        "id": "models_uncensored",
        "topic": "Modelos sem Censura",
        "content": """eddie-assistant baseado em dolphin-llama3:8b - sem censura.
        eddie-coder baseado em qwen2.5-coder:7b - apenas c√≥digo.
        Usar dolphin para assistente pessoal completo."""
    },
    {
        "id": "waha_whatsapp",
        "topic": "WAHA WhatsApp API",
        "content": """Docker: docker run -d --name waha -p 3001:3000 -e WAHA_NO_API_KEY=True devlikeapro/waha:latest
        Dashboard: http://192.168.15.2:3001/dashboard
        Usar engine WEBJS para QR code est√°vel."""
    },
    {
        "id": "model_profiles",
        "topic": "Perfis de Modelo",
        "content": """Perfis: assistant (pessoal), coder (c√≥digo), homelab (infra), fast (1.5b), advanced (16b).
        Auto-sele√ß√£o por palavras-chave no prompt.
        Comandos Telegram: /models, /profiles, /profile, /use"""
    },
    {
        "id": "ollama_commands",
        "topic": "Comandos Ollama",
        "content": """ollama list - listar modelos
        ollama create nome -f Modelfile - criar modelo
        ollama run modelo - testar modelo
        ollama show modelo - ver info"""
    }
]

def get_ollama_embedding(text: str) -> List[float]:
    """Gera embedding usando Ollama"""
    try:
        response = requests.post(
            f"{OLLAMA_URL}/api/embeddings",
            json={"model": "nomic-embed-text", "prompt": text},
            timeout=30
        )
        if response.status_code == 200:
            return response.json()["embedding"]
    except Exception as e:
        print(f"‚ö†Ô∏è Erro embedding: {e}")
    return None

def index_to_chromadb():
    """Indexa no ChromaDB usando Ollama embeddings"""
    print("üìö Conectando ao ChromaDB...")
    
    client = chromadb.PersistentClient(path=str(CHROMA_DIR))
    
    # Criar cole√ß√£o sem embedding function (vamos fornecer manualmente)
    try:
        collection = client.get_collection("eddie_knowledge_v2")
        print(f"üìä Cole√ß√£o existente: {collection.count()} docs")
    except:
        collection = client.create_collection(
            name="eddie_knowledge_v2",
            metadata={"hnsw:space": "cosine"}
        )
        print("üìä Nova cole√ß√£o criada")
    
    added = 0
    for item in KNOWLEDGE:
        print(f"  ‚Üí Processando: {item['topic'][:40]}...")
        
        # Gerar embedding
        text = f"{item['topic']}\n{item['content']}"
        embedding = get_ollama_embedding(text)
        
        if embedding:
            collection.upsert(
                ids=[item["id"]],
                documents=[text],
                embeddings=[embedding],
                metadatas=[{"topic": item["topic"], "date": datetime.now().isoformat()}]
            )
            added += 1
    
    print(f"‚úÖ Adicionados {added} documentos. Total: {collection.count()}")
    return collection.count()

def save_training_jsonl():
    """Salva dados de treinamento"""
    pairs = [
        ("Como integrar Open WebUI com Telegram?", "Use openwebui_integration.py que conecta ao Ollama (192.168.15.2:11434) com sele√ß√£o autom√°tica de modelo."),
        ("Qual modelo usar para assistente pessoal?", "Use eddie-assistant baseado em dolphin-llama3:8b, sem censura para uso pessoal."),
        ("Como configurar WAHA para WhatsApp?", "docker run -d --name waha -p 3001:3000 -e WAHA_NO_API_KEY=True devlikeapro/waha:latest. Dashboard em :3001/dashboard"),
        ("Como criar modelo restrito para c√≥digo?", "Use Modelfile com SYSTEM prompt restritivo. Exemplo: eddie-coder-strict.Modelfile"),
        ("Quais comandos do Telegram bot?", "/models (lista), /profiles (perfis), /profile <nome>, /use <modelo>, /auto_profile"),
        ("O QR Code do WhatsApp expira r√°pido?", "Use engine WEBJS: -e WHATSAPP_DEFAULT_ENGINE=WEBJS. Mais est√°vel que NOWEB."),
        ("Diferen√ßa eddie-assistant e eddie-coder?", "eddie-assistant (dolphin) sem censura para uso pessoal. eddie-coder (qwen) restrito a c√≥digo."),
        ("Onde ficam os servi√ßos?", "Ollama: 192.168.15.2:11434, Open WebUI: :3000, WAHA: :3001, Streamlit: localhost:8502"),
    ]
    
    filename = TRAINING_DIR / f"training_{datetime.now().strftime('%Y-%m-%d')}_knowledge.jsonl"
    with open(filename, "w") as f:
        for q, a in pairs:
            f.write(json.dumps({"prompt": q, "completion": a}, ensure_ascii=False) + "\n")
    
    print(f"‚úÖ Treino salvo: {filename} ({len(pairs)} pares)")
    return filename

def main():
    print("üöÄ Atualizando RAG e Treinamento...")
    print("=" * 50)
    
    # 1. Salvar treino
    print("\nüìù Salvando dados de treinamento...")
    save_training_jsonl()
    
    # 2. Indexar RAG
    print("\nüîç Indexando no ChromaDB...")
    index_to_chromadb()
    
    print("\n‚úÖ Conclu√≠do!")

if __name__ == "__main__":
    main()
